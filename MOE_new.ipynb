{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruC5_Zno7BIl",
        "outputId": "fea98fb2-d83c-4785-c00f-d1596e088a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zrnOYz2WWdX"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# L = nn.Parameter(torch.randn(4, 2, requires_grad=True))\n",
        "# U = nn.Parameter(torch.randn(2, 3, requires_grad=True))\n",
        "\n",
        "# W = torch.sigmoid(50 * (L @ U))  # Should allow grad\n",
        "# x = torch.randn(1, 3)\n",
        "# target = torch.randn(1, 4)\n",
        "\n",
        "# out = F.linear(x, W)\n",
        "# loss = F.mse_loss(out, target)\n",
        "# loss.backward()\n",
        "\n",
        "# print(L.grad)\n",
        "# print(U.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ4l9Vwdqa8M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Feature Extractor (ResNet-18)\n",
        "# ----------------------------\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=True)\n",
        "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Gating Network\n",
        "# ----------------------------\n",
        "class GatingNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, num_experts):\n",
        "        super(GatingNetwork, self).__init__()\n",
        "        self.fc = nn.Linear(input_dim, num_experts)\n",
        "\n",
        "    # def forward(self, x):\n",
        "    #     logits = self.fc(x)\n",
        "    #     # gumbel_noise = -torch.log(-torch.log(torch.rand_like(logits) + 1e-10) + 1e-10)\n",
        "    #     expert_scores = F.softmax((logits), dim=1)\n",
        "    #     expert_id = torch.argmax(expert_scores, dim=1)\n",
        "    #     return expert_id, expert_scores\n",
        "\n",
        "    def forward(self, x):\n",
        "      logits = self.fc(x)\n",
        "      gumbel_noise = -torch.log(-torch.log(torch.rand_like(logits) + 1e-10) + 1e-10)\n",
        "      expert_scores = F.softmax((logits + gumbel_noise) / 0.5, dim=-1)\n",
        "      # print(expert_scores)\n",
        "      # print(\"expert_scores: \",expert_scores)\n",
        "      return expert_scores  # shape [B, num_experts]\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Masked Feature Extractor\n",
        "# ----------------------------\n",
        "class MaskedLUFeatureExtractor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_experts, threshold=0.5, num_layers=4):\n",
        "        super(MaskedLUFeatureExtractor, self).__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.threshold = threshold\n",
        "\n",
        "        # Create real linear layers (separate per expert and layer)\n",
        "        self.linear_layers = nn.ModuleDict()\n",
        "\n",
        "        # Create L, U, and b for mask generation\n",
        "        self.L_matrices = nn.ParameterDict()\n",
        "        self.U_matrices = nn.ParameterDict()\n",
        "        self.bias_masks = nn.ParameterDict()\n",
        "\n",
        "        for expert_id in range(num_experts):\n",
        "            for layer_idx in range(num_layers):\n",
        "                d_in = input_dim if layer_idx == 0 else hidden_dim\n",
        "                d_out = hidden_dim\n",
        "                k = max(d_in, d_out)\n",
        "\n",
        "                # Initialize linear layer for this expert and layer\n",
        "                lin_key = f\"expert{expert_id}_layer{layer_idx}_linear\"\n",
        "                self.linear_layers[lin_key] = nn.Linear(d_in, d_out)\n",
        "\n",
        "                # L, U, and bias mask\n",
        "                l_key = f\"expert{expert_id}_layer{layer_idx}_L\"\n",
        "                u_key = f\"expert{expert_id}_layer{layer_idx}_U\"\n",
        "                b_key = f\"expert{expert_id}_layer{layer_idx}_b\"\n",
        "\n",
        "                self.L_matrices[l_key] = nn.Parameter(torch.tril(torch.randn(d_out, k)))\n",
        "                self.U_matrices[u_key] = nn.Parameter(torch.randn(k, d_in))\n",
        "                self.bias_masks[b_key] = nn.Parameter(torch.zeros(d_out))\n",
        "\n",
        "    def forward(self, x, expert_id):\n",
        "        for i in range(self.num_layers):\n",
        "            lin_key = f\"expert{expert_id}_layer{i}_linear\"\n",
        "            l_key = f\"expert{expert_id}_layer{i}_L\"\n",
        "            u_key = f\"expert{expert_id}_layer{i}_U\"\n",
        "            b_key = f\"expert{expert_id}_layer{i}_b\"\n",
        "\n",
        "            linear = self.linear_layers[lin_key]\n",
        "            weight = linear.weight         # [d_out, d_in]\n",
        "            bias = linear.bias             # [d_out]\n",
        "\n",
        "            # Generate mask using sigmoid(50 * L @ U)\n",
        "            L = self.L_matrices[l_key]     # [d_out, k]\n",
        "            U = self.U_matrices[u_key]     # [k, d_in]\n",
        "            b_mask = self.bias_masks[b_key]  # [d_out]\n",
        "\n",
        "            W_mask = torch.sigmoid(10 * (L @ U))\n",
        "            # print(W_mask)          # [d_out, d_in]\n",
        "            b_mask = torch.sigmoid(b_mask)                  # [d_out]\n",
        "\n",
        "            # Apply mask\n",
        "            masked_weight = weight * W_mask                 # [d_out, d_in]\n",
        "            masked_bias = bias * b_mask                     # [d_out]\n",
        "\n",
        "            # Linear transformation with masked weights and biases\n",
        "            x = F.linear(x, masked_weight, masked_bias)\n",
        "            x = F.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# class MaskedLUFeatureExtractor(nn.Module):\n",
        "#     def __init__(self, input_dim, hidden_dim, num_experts, num_layers=4):\n",
        "#         super(MaskedLUFeatureExtractor, self).__init__()\n",
        "#         self.num_experts = num_experts\n",
        "#         self.num_layers = num_layers\n",
        "#         self.hidden_dim = hidden_dim\n",
        "#         self.input_dim = input_dim\n",
        "\n",
        "#         self.linear_layers = nn.ModuleDict()\n",
        "\n",
        "#         # Hardcoded masks per expert and layer\n",
        "#         self.weight_masks = {}  # shape: [d_out, d_in]\n",
        "#         self.bias_masks = {}    # shape: [d_out]\n",
        "\n",
        "#         for expert_id in range(num_experts):\n",
        "#             self.weight_masks[expert_id] = {}\n",
        "#             self.bias_masks[expert_id] = {}\n",
        "#             for layer_idx in range(num_layers):\n",
        "#                 d_in = input_dim if layer_idx == 0 else hidden_dim\n",
        "#                 d_out = hidden_dim\n",
        "\n",
        "#                 lin_key = f\"expert{expert_id}_layer{layer_idx}_linear\"\n",
        "#                 self.linear_layers[lin_key] = nn.Linear(d_in, d_out)\n",
        "\n",
        "#                 # Example: Mask half of the weights/biases randomly\n",
        "#                 torch.manual_seed(expert_id * 10 + layer_idx)  # for reproducibility\n",
        "#                 # self.weight_masks[expert_id][layer_idx] = (torch.rand(d_out, d_in) > 0.5).float()\n",
        "#                 # # you are doing (dout_din) because PyTorch internally does (batch_size *x) * W^T, during matrix multiplication\n",
        "#                 # self.bias_masks[expert_id][layer_idx] = (torch.rand(d_out) > 0.5).float()\n",
        "\n",
        "#                 self.weight_masks[expert_id][layer_idx] = torch.ones(d_out, d_in)\n",
        "#                 self.bias_masks[expert_id][layer_idx] = torch.ones(d_out)\n",
        "\n",
        "#     def forward(self, x, expert_id):\n",
        "#         for i in range(self.num_layers):\n",
        "#             lin_key = f\"expert{expert_id}_layer{i}_linear\"\n",
        "#             linear = self.linear_layers[lin_key]\n",
        "#             weight = linear.weight\n",
        "#             bias = linear.bias\n",
        "\n",
        "#             W_mask = self.weight_masks[expert_id][i].to(weight.device)\n",
        "#             b_mask = self.bias_masks[expert_id][i].to(bias.device)\n",
        "\n",
        "#             masked_weight = weight * W_mask\n",
        "#             masked_bias = bias * b_mask\n",
        "#             # print(masked_weight.size())\n",
        "#             # print(x.size())\n",
        "#             x = F.linear(x, masked_weight, masked_bias)\n",
        "#             x = F.relu(x)\n",
        "\n",
        "#         return x\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Shared Classification Layer\n",
        "# ----------------------------\n",
        "class SharedClassifier(nn.Module):\n",
        "    def __init__(self, hidden_dim, output_dim):\n",
        "        super(SharedClassifier, self).__init__()\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "        # return F.softmax(self.fc(x), dim=1)\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Mixture of Experts\n",
        "# ----------------------------\n",
        "class MixtureOfExperts(nn.Module):\n",
        "    def __init__(self, feature_dim, hidden_dim, num_experts=1, output_dim=200):\n",
        "        super(MixtureOfExperts, self).__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.feature_extractor = FeatureExtractor()\n",
        "        self.gating_network = GatingNetwork(feature_dim, num_experts)\n",
        "        # self.masked_feature_extractor = MaskedFeatureExtractor(feature_dim, hidden_dim, num_experts)\n",
        "        self.masked_feature_extractor = MaskedLUFeatureExtractor(feature_dim, hidden_dim, num_experts)\n",
        "        self.classifier = SharedClassifier(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "      features = self.feature_extractor(x)             # [B, feature_dim]\n",
        "      expert_scores = self.gating_network(features)    # [B, num_experts]\n",
        "\n",
        "      expert_outputs = []\n",
        "      for i in range(self.num_experts):\n",
        "          out = self.masked_feature_extractor(features, expert_id=i)  # [B, hidden_dim]\n",
        "          expert_outputs.append(out.unsqueeze(1))  # shape [B, 1, hidden_dim]\n",
        "\n",
        "      expert_outputs = torch.cat(expert_outputs, dim=1)   # [B, num_experts, hidden_dim]\n",
        "      expert_scores = expert_scores.unsqueeze(2)          # [B, num_experts, 1]\n",
        "\n",
        "      weighted_features = (expert_outputs * expert_scores).sum(dim=1)  # [B, hidden_dim]\n",
        "      logits = self.classifier(weighted_features)                      # [B, output_dim]\n",
        "      return logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sM6jvWK7qa8O"
      },
      "outputs": [],
      "source": [
        "def full_training(model, dataloader, criterion, device, optimizer, num_epochs=50, log_interval=100):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            # print(\"Outputs: \",outputs)\n",
        "            # print(\"Labels: \",labels)\n",
        "            loss = criterion(outputs, labels)\n",
        "            # print(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            # print(\"Predicted \",predicted)\n",
        "            # print(\"Labels: \",labels)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            if batch_idx % log_interval == 0:\n",
        "                print(f\"Batch [{batch_idx}/{len(dataloader)}] - Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "        # for name, param in model.named_parameters():\n",
        "        #   print(f\"{name}: requires : {param.requires_grad} | grad not None? {param.grad is not None} | grad norm: {param.grad.norm() if param.grad is not None else 'NA'}\")\n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        epoch_accuracy = 100. * correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xICCMHDCqa8P"
      },
      "outputs": [],
      "source": [
        "# def retrain_with_mask(model, dataloader, criterion, optimizer, device, num_epochs=5, log_interval=10):\n",
        "#     model.train()\n",
        "\n",
        "#     for epoch in range(num_epochs):\n",
        "#         running_loss = 0.0\n",
        "#         correct, total = 0, 0\n",
        "\n",
        "#         for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "#             images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(images)\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             running_loss += loss.item()\n",
        "#             _, predicted = outputs.max(1)\n",
        "#             total += labels.size(0)\n",
        "#             correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "#             if batch_idx % log_interval == 0:\n",
        "#                 print(f\"Batch [{batch_idx}/{len(dataloader)}] - Loss: {loss.item():.4f}\")\n",
        "\n",
        "#         epoch_loss = running_loss / len(dataloader)\n",
        "#         epoch_accuracy = 100. * correct / total\n",
        "#         print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAPPxKiaqa8P"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Set device ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- Transforms ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# --- Load individual datasets ---\n",
        "cub_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/cubs_cropped/train', transform=transform)\n",
        "flowers_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/flowers/train', transform=transform)\n",
        "\n",
        "# --- Merge datasets WITHOUT offsetting class labels ---\n",
        "# ConcatDataset simply creates a virtual concatenation of the datasets\n",
        "combined_dataset = ConcatDataset([cub_dataset, flowers_dataset])\n",
        "# combined_dataset = ConcatDataset([cub_dataset])\n",
        "combined_loader = DataLoader(combined_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# --- Determine total number of classes from combined dataset ---\n",
        "# Here we assume that each dataset's labels remain unchanged.\n",
        "# all_targets = []\n",
        "# for ds in [cub_dataset, flowers_dataset]:\n",
        "#     all_targets.extend(ds.targets)\n",
        "#     print(ds.targets)\n",
        "# # The total number of classes is the maximum label value + 1 (if labels are 0-indexed)\n",
        "# total_classes = np.max(all_targets) + 1\n",
        "# print(f\"Total classes (combined): {total_classes}\")\n",
        "\n",
        "# --- Initialize the Mixture of Experts model with the combined output dim ---\n",
        "model = MixtureOfExperts(feature_dim=512, hidden_dim=256, num_experts=2, output_dim=200).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.named_parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c1IOkFGKiaq6",
        "outputId": "d87c1bff-a875-4fef-be2c-511b7e18b6bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== Training on Combined CUB + Flowers Dataset ====\n",
            "Batch [0/188] - Loss: 5.2955\n",
            "Batch [10/188] - Loss: 5.3042\n",
            "Batch [20/188] - Loss: 5.2983\n",
            "Batch [30/188] - Loss: 5.3083\n",
            "Batch [40/188] - Loss: 5.2848\n",
            "Batch [50/188] - Loss: 5.2003\n",
            "Batch [60/188] - Loss: 5.0961\n",
            "Batch [70/188] - Loss: 5.1945\n",
            "Batch [80/188] - Loss: 5.1006\n",
            "Batch [90/188] - Loss: 5.3410\n",
            "Batch [100/188] - Loss: 4.9658\n",
            "Batch [110/188] - Loss: 5.0655\n",
            "Batch [120/188] - Loss: 5.2119\n",
            "Batch [130/188] - Loss: 4.9874\n",
            "Batch [140/188] - Loss: 4.9123\n",
            "Batch [150/188] - Loss: 4.8651\n",
            "Batch [160/188] - Loss: 4.8898\n",
            "Batch [170/188] - Loss: 4.7365\n",
            "Batch [180/188] - Loss: 5.0805\n",
            "Epoch [1/50] - Loss: 5.1071, Accuracy: 1.02%\n",
            "Batch [0/188] - Loss: 4.7806\n",
            "Batch [10/188] - Loss: 4.7949\n",
            "Batch [20/188] - Loss: 4.9834\n",
            "Batch [30/188] - Loss: 4.6368\n",
            "Batch [40/188] - Loss: 4.6505\n",
            "Batch [50/188] - Loss: 4.9260\n",
            "Batch [60/188] - Loss: 4.7647\n",
            "Batch [70/188] - Loss: 4.8973\n",
            "Batch [80/188] - Loss: 4.7679\n",
            "Batch [90/188] - Loss: 5.0299\n",
            "Batch [100/188] - Loss: 4.6020\n",
            "Batch [110/188] - Loss: 4.6456\n",
            "Batch [120/188] - Loss: 4.6741\n",
            "Batch [130/188] - Loss: 4.5953\n",
            "Batch [140/188] - Loss: 4.7112\n",
            "Batch [150/188] - Loss: 4.7369\n",
            "Batch [160/188] - Loss: 4.5923\n",
            "Batch [170/188] - Loss: 4.9322\n",
            "Batch [180/188] - Loss: 4.8668\n",
            "Epoch [2/50] - Loss: 4.7609, Accuracy: 1.40%\n",
            "Batch [0/188] - Loss: 4.6559\n",
            "Batch [10/188] - Loss: 4.6844\n",
            "Batch [20/188] - Loss: 4.6391\n",
            "Batch [30/188] - Loss: 4.6419\n",
            "Batch [40/188] - Loss: 4.7160\n",
            "Batch [50/188] - Loss: 4.5179\n",
            "Batch [60/188] - Loss: 4.5985\n",
            "Batch [70/188] - Loss: 4.6118\n",
            "Batch [80/188] - Loss: 4.9333\n",
            "Batch [90/188] - Loss: 4.6587\n",
            "Batch [100/188] - Loss: 4.7459\n",
            "Batch [110/188] - Loss: 4.5694\n",
            "Batch [120/188] - Loss: 4.5451\n",
            "Batch [130/188] - Loss: 4.4461\n",
            "Batch [140/188] - Loss: 4.5420\n",
            "Batch [150/188] - Loss: 4.6464\n",
            "Batch [160/188] - Loss: 4.6089\n",
            "Batch [170/188] - Loss: 4.5778\n",
            "Batch [180/188] - Loss: 4.6934\n",
            "Epoch [3/50] - Loss: 4.6047, Accuracy: 1.89%\n",
            "Batch [0/188] - Loss: 4.6237\n",
            "Batch [10/188] - Loss: 4.2683\n",
            "Batch [20/188] - Loss: 4.1846\n",
            "Batch [30/188] - Loss: 4.4078\n",
            "Batch [40/188] - Loss: 4.5072\n",
            "Batch [50/188] - Loss: 4.4265\n",
            "Batch [60/188] - Loss: 4.7589\n",
            "Batch [70/188] - Loss: 4.7269\n",
            "Batch [80/188] - Loss: 4.4905\n",
            "Batch [90/188] - Loss: 4.5422\n",
            "Batch [100/188] - Loss: 4.3597\n",
            "Batch [110/188] - Loss: 4.4905\n",
            "Batch [120/188] - Loss: 4.5225\n",
            "Batch [130/188] - Loss: 4.5584\n",
            "Batch [140/188] - Loss: 4.6804\n",
            "Batch [150/188] - Loss: 4.3809\n",
            "Batch [160/188] - Loss: 4.4883\n",
            "Batch [170/188] - Loss: 4.3524\n",
            "Batch [180/188] - Loss: 4.3033\n",
            "Epoch [4/50] - Loss: 4.4820, Accuracy: 2.42%\n",
            "Batch [0/188] - Loss: 4.3490\n",
            "Batch [10/188] - Loss: 4.4179\n",
            "Batch [20/188] - Loss: 4.2707\n",
            "Batch [30/188] - Loss: 4.2830\n",
            "Batch [40/188] - Loss: 4.4259\n",
            "Batch [50/188] - Loss: 4.5293\n",
            "Batch [60/188] - Loss: 4.2626\n",
            "Batch [70/188] - Loss: 4.0654\n",
            "Batch [80/188] - Loss: 4.0770\n",
            "Batch [90/188] - Loss: 4.2696\n",
            "Batch [100/188] - Loss: 4.5559\n",
            "Batch [110/188] - Loss: 4.5359\n",
            "Batch [120/188] - Loss: 4.4627\n",
            "Batch [130/188] - Loss: 4.4768\n",
            "Batch [140/188] - Loss: 4.1697\n",
            "Batch [150/188] - Loss: 4.6155\n",
            "Batch [160/188] - Loss: 4.4000\n",
            "Batch [170/188] - Loss: 4.3440\n",
            "Batch [180/188] - Loss: 4.2553\n",
            "Epoch [5/50] - Loss: 4.3729, Accuracy: 3.02%\n",
            "Batch [0/188] - Loss: 4.3119\n",
            "Batch [10/188] - Loss: 4.2256\n",
            "Batch [20/188] - Loss: 4.0894\n",
            "Batch [30/188] - Loss: 4.2564\n",
            "Batch [40/188] - Loss: 4.4113\n",
            "Batch [50/188] - Loss: 4.0817\n",
            "Batch [60/188] - Loss: 4.2441\n",
            "Batch [70/188] - Loss: 4.0878\n",
            "Batch [80/188] - Loss: 4.0564\n",
            "Batch [90/188] - Loss: 4.0467\n",
            "Batch [100/188] - Loss: 4.5862\n",
            "Batch [110/188] - Loss: 4.2214\n",
            "Batch [120/188] - Loss: 4.1869\n",
            "Batch [130/188] - Loss: 4.3966\n",
            "Batch [140/188] - Loss: 4.0049\n",
            "Batch [150/188] - Loss: 4.1594\n",
            "Batch [160/188] - Loss: 4.3755\n",
            "Batch [170/188] - Loss: 4.3533\n",
            "Batch [180/188] - Loss: 4.2939\n",
            "Epoch [6/50] - Loss: 4.2456, Accuracy: 3.22%\n",
            "Batch [0/188] - Loss: 4.0216\n",
            "Batch [10/188] - Loss: 4.1991\n",
            "Batch [20/188] - Loss: 4.0539\n",
            "Batch [30/188] - Loss: 4.3293\n",
            "Batch [40/188] - Loss: 4.2919\n",
            "Batch [50/188] - Loss: 4.1892\n",
            "Batch [60/188] - Loss: 3.9672\n",
            "Batch [70/188] - Loss: 4.2102\n",
            "Batch [80/188] - Loss: 4.2145\n",
            "Batch [90/188] - Loss: 4.0789\n",
            "Batch [100/188] - Loss: 3.7901\n",
            "Batch [110/188] - Loss: 4.9535\n",
            "Batch [120/188] - Loss: 4.2441\n",
            "Batch [130/188] - Loss: 4.1894\n",
            "Batch [140/188] - Loss: 3.7225\n",
            "Batch [150/188] - Loss: 4.0058\n",
            "Batch [160/188] - Loss: 4.0952\n",
            "Batch [170/188] - Loss: 3.9056\n",
            "Batch [180/188] - Loss: 3.8704\n",
            "Epoch [7/50] - Loss: 4.1115, Accuracy: 4.67%\n",
            "Batch [0/188] - Loss: 4.0383\n",
            "Batch [10/188] - Loss: 3.9401\n",
            "Batch [20/188] - Loss: 3.9432\n",
            "Batch [30/188] - Loss: 4.0246\n",
            "Batch [40/188] - Loss: 3.8896\n",
            "Batch [50/188] - Loss: 3.8781\n",
            "Batch [60/188] - Loss: 4.2303\n",
            "Batch [70/188] - Loss: 4.0184\n",
            "Batch [80/188] - Loss: 3.9859\n",
            "Batch [90/188] - Loss: 4.1775\n",
            "Batch [100/188] - Loss: 3.9488\n",
            "Batch [110/188] - Loss: 3.6910\n",
            "Batch [120/188] - Loss: 3.7660\n",
            "Batch [130/188] - Loss: 3.6931\n",
            "Batch [140/188] - Loss: 3.8390\n",
            "Batch [150/188] - Loss: 3.8071\n",
            "Batch [160/188] - Loss: 3.8949\n",
            "Batch [170/188] - Loss: 3.8891\n",
            "Batch [180/188] - Loss: 4.0309\n",
            "Epoch [8/50] - Loss: 3.9707, Accuracy: 5.11%\n",
            "Batch [0/188] - Loss: 3.5249\n",
            "Batch [10/188] - Loss: 4.3087\n",
            "Batch [20/188] - Loss: 3.9379\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ccf68692c916>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- Full Training on Merged Dataset ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n==== Training on Combined CUB + Flowers Dataset ====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfull_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-d2ae922fb6cf>\u001b[0m in \u001b[0;36mfull_training\u001b[0;34m(model, dataloader, criterion, device, optimizer, num_epochs, log_interval)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m    244\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mdeprecate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"transparency\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# --- Full Training on Merged Dataset ---\n",
        "print(\"\\n==== Training on Combined CUB + Flowers Dataset ====\")\n",
        "full_training(model, combined_loader, criterion, device, optimizer, num_epochs=50, log_interval=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmXT9_x-qa8P"
      },
      "outputs": [],
      "source": [
        "# save the model that has been trained in drive\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/model_1_expert_1_task_50_epochs.pth\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}